{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyFmgzPpDl_p"
      },
      "source": [
        "# 0. Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eusb-jRT9b-9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "\n",
        "ROOT_PATH = \"./data\"\n",
        "FILE_NAME = \"data_ilt.json\"\n",
        "MODEL_NAME = \"llama-3.1-8b\"\n",
        "DATA_FILE_PATH = ROOT_PATH + \"/\" + MODEL_NAME + \"/\" + FILE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE3YqyQyDpXY"
      },
      "source": [
        "# 1. Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5reHUh0DkDN"
      },
      "outputs": [],
      "source": [
        "def load_data_from_json(file_path):\n",
        "    \"\"\"Loads data from a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found - {file_path}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Invalid JSON format in file - {file_path}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXSpcqQuDi0x"
      },
      "outputs": [],
      "source": [
        "def save_list_to_json(data_list, file_path):\n",
        "    \"\"\"Saves a list of IDs to a JSON file.\"\"\"\n",
        "    try:\n",
        "        # Create the directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data_list, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"Data successfully saved to {file_path}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Failed to save {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuY6noMcDhnt"
      },
      "outputs": [],
      "source": [
        "def check_answer_consistency(data_dict):\n",
        "    \"\"\"\n",
        "    Checks if the values in the 'answers' list for each ID are exactly identical.\n",
        "    - e.g., [\"A\", \"A\", \"A\"] -> Consistent\n",
        "    - e.g., [\"A\", \" A\", \"A\"] -> Inconsistent (due to whitespace)\n",
        "    \"\"\"\n",
        "    if not data_dict:\n",
        "        return None\n",
        "\n",
        "    consistent_ids = []\n",
        "    inconsistent_ids = []\n",
        "\n",
        "    for unique_id, element_data in data_dict.items():\n",
        "        answers = element_data.get(\"answers\")\n",
        "\n",
        "        # Skip if 'answers' key is missing or the value is not a list.\n",
        "        if not isinstance(answers, list) or not answers:\n",
        "            continue\n",
        "\n",
        "        # Efficiently check if all elements in the list are identical using a set.\n",
        "        # If the set length is <= 1 (list is empty, has one item, or all items are the same),\n",
        "        # it's considered consistent.\n",
        "        if len(set(answers)) <= 1:\n",
        "            consistent_ids.append(unique_id)\n",
        "        else:\n",
        "            inconsistent_ids.append(unique_id)\n",
        "\n",
        "    return {\n",
        "        \"consistent_ids\": consistent_ids,\n",
        "        \"inconsistent_ids\": inconsistent_ids\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtZBkE4LORnD"
      },
      "outputs": [],
      "source": [
        "def check_normalized_answer_consistency_with_special_tokens(data_dict, special_tokens):\n",
        "    \"\"\"\n",
        "    Checks if the values in the 'answers' list for each ID are identical\n",
        "    after removing specific whitespace tokens.\n",
        "\n",
        "    - Example tokens to remove: ' ' (U+2581), 'Ġ' (U+0120)\n",
        "    - e.g., [\"ĠA\", \" A\", \"A\"] -> [\"A\", \"A\", \"A\"] after cleaning -> Consistent\n",
        "    - e.g., [\"A\", \" B\"] -> [\"A\", \"B\"] after cleaning -> Inconsistent\n",
        "    \"\"\"\n",
        "    if not data_dict:\n",
        "        return None\n",
        "\n",
        "    # List of special tokens to remove\n",
        "    # Other tokens can be added to this list as needed.\n",
        "    SPECIAL_TOKENS_TO_REMOVE = special_tokens\n",
        "\n",
        "    consistent_ids = []\n",
        "    inconsistent_ids = []\n",
        "\n",
        "    for unique_id, element_data in data_dict.items():\n",
        "        answers = element_data.get(\"answers\")\n",
        "\n",
        "        if not isinstance(answers, list) or not answers:\n",
        "            continue\n",
        "\n",
        "        # Function to remove special tokens from each answer\n",
        "        def clean_answer(answer_str):\n",
        "            if not isinstance(answer_str, str):\n",
        "                return answer_str # Return original if not a string\n",
        "\n",
        "            cleaned_str = answer_str\n",
        "            for token in SPECIAL_TOKENS_TO_REMOVE:\n",
        "                cleaned_str = cleaned_str.replace(token, \"\")\n",
        "            return cleaned_str\n",
        "\n",
        "        # Clean each answer using a list comprehension.\n",
        "        cleaned_answers = [clean_answer(ans) for ans in answers]\n",
        "\n",
        "        # Efficiently check if all elements in the cleaned list are identical using a set.\n",
        "        if len(set(cleaned_answers)) <= 1:\n",
        "            consistent_ids.append(unique_id)\n",
        "        else:\n",
        "            inconsistent_ids.append(unique_id)\n",
        "\n",
        "    return {\n",
        "        \"consistent_ids\": consistent_ids,\n",
        "        \"inconsistent_ids\": inconsistent_ids\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJn2D7DsDcyH"
      },
      "outputs": [],
      "source": [
        "def run_analysis(data_path):\n",
        "    \"\"\"Runs the entire analysis process and summarizes/saves the results.\"\"\"\n",
        "    print(f\"--- Analysis Start: {data_path} ---\")\n",
        "\n",
        "    # 1. Load data\n",
        "    main_data = load_data_from_json(data_path)\n",
        "    if not main_data:\n",
        "        print(\"Analysis stopped.\")\n",
        "        return\n",
        "\n",
        "    # 2. Analyze Answer Consistency\n",
        "    results = check_answer_consistency(main_data)\n",
        "    if not results:\n",
        "        print(\"No data to analyze.\")\n",
        "        return\n",
        "\n",
        "    # 3. Print result summary\n",
        "    consistent_count = len(results[\"consistent_ids\"])\n",
        "    inconsistent_count = len(results[\"inconsistent_ids\"])\n",
        "    total_count = consistent_count + inconsistent_count\n",
        "\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"--- Answer Consistency Analysis Results ---\")\n",
        "    if total_count > 0:\n",
        "        print(f\"Total IDs processed: {total_count}\")\n",
        "        print(f\"  - Consistent IDs: {consistent_count} ({consistent_count/total_count:.2%})\")\n",
        "        print(f\"  - Inconsistent IDs: {inconsistent_count} ({inconsistent_count/total_count:.2%})\")\n",
        "    else:\n",
        "        print(\"No valid IDs to analyze.\")\n",
        "    print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "    # 4. Save ID lists to files\n",
        "    output_dir = os.path.dirname(data_path)\n",
        "    save_list_to_json(results[\"consistent_ids\"], os.path.join(output_dir, \"consistent_ids_converted.json\"))\n",
        "    save_list_to_json(results[\"inconsistent_ids\"], os.path.join(output_dir, \"inconsistent_ids_converted.json\"))\n",
        "\n",
        "    print(\"\\n--- Analysis Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmvWlmrvPIgV"
      },
      "outputs": [],
      "source": [
        "def run_normalized_analysis(data_path, special_tokens):\n",
        "    \"\"\"\n",
        "    Loads data, runs normalization-based consistency analysis,\n",
        "    and summarizes/saves the results.\n",
        "    \"\"\"\n",
        "    print(f\"--- Normalization-Based Analysis Start: {data_path} ---\")\n",
        "\n",
        "    # 1. Load data\n",
        "    main_data = load_data_from_json(data_path)\n",
        "    if not main_data:\n",
        "        print(\"Analysis stopped.\")\n",
        "        return\n",
        "\n",
        "    # 2. Run Answer consistency analysis after normalization\n",
        "    # ✅ Key Change: Calls the new function that includes normalization.\n",
        "    results = check_normalized_answer_consistency_with_special_tokens(main_data, special_tokens)\n",
        "    if not results:\n",
        "        print(\"No data to analyze.\")\n",
        "        return\n",
        "\n",
        "    # 3. Print result summary\n",
        "    consistent_count = len(results[\"consistent_ids\"])\n",
        "    inconsistent_count = len(results[\"inconsistent_ids\"])\n",
        "    total_count = consistent_count + inconsistent_count\n",
        "\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    # ✅ Changed output message: Clarifies the type of analysis.\n",
        "    print(\"--- Answer Consistency Analysis Results (After Normalization) ---\")\n",
        "    if total_count > 0:\n",
        "        print(f\"Total IDs processed: {total_count}\")\n",
        "        print(f\"  - ✅ Consistent IDs: {consistent_count} ({consistent_count/total_count:.2%})\")\n",
        "        print(f\"  - ❌ Inconsistent IDs: {inconsistent_count} ({inconsistent_count/total_count:.2%})\")\n",
        "    else:\n",
        "        print(\"No valid IDs to analyze.\")\n",
        "    print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "    # 4. Save ID lists to files\n",
        "    output_dir = os.path.dirname(data_path)\n",
        "    # ✅ Filename Change: Specifies the analysis type in the filename.\n",
        "    consistent_filename = \"normalized_consistent_ids.json\"\n",
        "    inconsistent_filename = \"normalized_inconsistent_ids.json\"\n",
        "\n",
        "    save_list_to_json(results[\"consistent_ids\"], os.path.join(output_dir, consistent_filename))\n",
        "    save_list_to_json(results[\"inconsistent_ids\"], os.path.join(output_dir, inconsistent_filename))\n",
        "\n",
        "    print(\"\\n--- Analysis Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWAbZVX6DrNV"
      },
      "source": [
        "# 2. Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WmUtizLrER3W",
        "outputId": "d7a958c7-0171-4ece-8647-b251db9ed1c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/data_ilt_converted.json'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_FILE_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8MNHFBIAbti",
        "outputId": "c2509610-865d-42b6-d5e8-76ce74af32d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 분석 시작: /content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/data_ilt_converted.json ---\n",
            "\n",
            "--------------------------------------------------\n",
            "--- Answer 일관성 분석 결과 ---\n",
            "처리된 총 ID: 977\n",
            "  - Consistent IDs: 320개 (32.75%)\n",
            "  - Inconsistent IDs: 657개 (67.25%)\n",
            "--------------------------------------------------\n",
            "\n",
            "데이터가 /content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/consistent_ids_converted.json에 성공적으로 저장되었습니다.\n",
            "데이터가 /content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/inconsistent_ids_converted.json에 성공적으로 저장되었습니다.\n",
            "\n",
            "--- 분석 완료 ---\n"
          ]
        }
      ],
      "source": [
        "run_analysis(DATA_FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcN-C6z6PTAn"
      },
      "source": [
        "# 3. Run Normalized CLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9dHwecnpP3wB",
        "outputId": "9568b499-c2bc-49a1-86bb-1bea22ca65ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/data_ilt_converted.json'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_FILE_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YUf-XENEfJg"
      },
      "outputs": [],
      "source": [
        "special_tokens = ['▁', 'Ġ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp_26ZEUP6i8",
        "outputId": "916eac95-3577-4323-afc6-08f6f7cf315d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 정규화 기반 분석 시작: /content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/data_ilt_converted.json ---\n",
            "\n",
            "--------------------------------------------------\n",
            "--- 정규화(Normalization) 후 Answer 일관성 분석 결과 ---\n",
            "처리된 총 ID: 977\n",
            "  - ✅ Consistent IDs: 320개 (32.75%)\n",
            "  - ❌ Inconsistent IDs: 657개 (67.25%)\n",
            "--------------------------------------------------\n",
            "\n",
            "데이터가 /content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/normalized_consistent_ids_converted.json에 성공적으로 저장되었습니다.\n",
            "데이터가 /content/drive/MyDrive/KAIRI_Experiment/Prompt_Bias/llama-3.1-8b/normalized_inconsistent_ids_converted.json에 성공적으로 저장되었습니다.\n",
            "\n",
            "--- 분석 완료 ---\n"
          ]
        }
      ],
      "source": [
        "run_normalized_analysis(DATA_FILE_PATH, special_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmMpkNWCQHbp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}